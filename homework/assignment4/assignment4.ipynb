{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d808aafd",
   "metadata": {},
   "source": [
    "# 1. Logistic Regression\n",
    "\n",
    "(a) \n",
    "> (10 points) Do natural log transform of the PFOS variable in file\n",
    "pfas.csv and store the results as a new variable log PFOS in the\n",
    "data file. Standardize the variables x=[log PFOS, age, gender, BMI]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "740fb93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.formula.api as api\n",
    "import statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73fc409a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"pfas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84aecb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoscale(df, variables_to_scale):\n",
    "    \"\"\"standardizes variables\"\"\"\n",
    "    for variable in variables_to_scale:\n",
    "        df[variable] = ( df[variable] - np.mean(df[variable]) ) / np.std(df[variable])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a6b566f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"log_PFOS\"] = np.log2(df[\"PFOS\"])\n",
    "standard_df = autoscale(df, [\"log_PFOS\", \"age\", \"gender\", \"BMI\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5ccfa6",
   "metadata": {},
   "source": [
    "### Numerical Solution\n",
    "(b) \n",
    "> (35 points) Use y=disease and the standardized x=[PFOS, age,\n",
    "gender, BMI] to write and debug your own gradient descent algorithm for logistic regression. Your algorithm should export the\n",
    "learned parameters in the θ vector. Note that you can modify the\n",
    "gradient descent algorithm that you have written for the linear re-\n",
    "gression algorithm to achieve logistic regression.\n",
    "\n",
    "#### Initalize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "7d710001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disease\n",
      " [0 0 0 0 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0 1 0 1 1 0 0 1 0 1 0 0 0 0 1 0 1\n",
      " 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 0 0 1 1 0 1 1 0 0\n",
      " 0 1 1 1 1 1 1 0 1 0 0 1 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 1 1 1 0 0 1 1 1 0\n",
      " 0 1 0 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0 0 1 1 0 1 0 1 1\n",
      " 0 1 1 0 1 0 0 0 1 0 1 1 0 1 0 1 0 0 1 1 0 0 1 1 0 1 0 1 0 0 1 0 1 1 0 1 1\n",
      " 0 1 1 1 1 0 0 0 0 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 1 0 0 0 1 1 0 1 0 1 1\n",
      " 1 1 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 1 0 1 1 0 0 0 1 1 0 0\n",
      " 1 1 0 0 1 0 0 0 0 1 0 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1\n",
      " 0 0 1 0]\n",
      "     intercept|    PFOS   |   age     |  gender    |    BMI\n",
      " [[ 0.90375231 -1.06321047 -1.06191317 -0.78453458]\n",
      " [-0.99778188  0.96375408 -1.06191317 -1.18985472]\n",
      " [-0.24350772  0.31512542  0.94169658 -0.5470809 ]\n",
      " ...\n",
      " [-0.24248557  0.396204    0.94169658  0.07829738]\n",
      " [-0.23195204  0.15296826  0.94169658  0.8139823 ]\n",
      " [ 0.29556023  0.80159691 -1.06191317  0.33858428]]\n"
     ]
    }
   ],
   "source": [
    "Y = df[\"disease\"].to_numpy()\n",
    "X = df.loc[:,[\"log_PFOS\", \"age\", \"gender\", \"BMI\"]].to_numpy()\n",
    "## add intercept\n",
    "X_with_intercept = np.insert( X, 0, np.array([1]*X.shape[0]), axis = 1 )\n",
    "\n",
    "\n",
    "\n",
    "print(\"disease\\n\", Y)\n",
    "print(\"     intercept|    PFOS   |   age     |  gender    |    BMI\\n\",X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373675a3",
   "metadata": {},
   "source": [
    "#### Sigmoid\n",
    "\n",
    "$ g(B^Tx)= \\frac{1}{1+e^{-(B^Tx)}}$\n",
    "\n",
    "$B^Tx=B_0x_0+B_1x_1+...+B_nx_n$\n",
    "\n",
    "$x_0=1$\n",
    "\n",
    "\n",
    "$$\n",
    "y = \\begin{cases}\n",
    "    \\text{1 if} & B^Tx\\text{ ≥ 0} \\\\\n",
    "    \\text{0 if} & B^Tx\\text{< 0} \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "\n",
    "#### Cost Function\n",
    "\n",
    "$i$ is a row $j$ is a column\n",
    "\n",
    "$ J(B) = -\\frac{1}{m} \\sum_{i=1}^m [y_i ln(\\frac{1}{1+e^{-(B^Tx)}}) + (1-y_i)ln(\\frac{1}{1+e^{-(B^Tx)}})]$\n",
    "\n",
    "$ B_j := B_j-α(\\frac{∂J(B)}{∂B_j}) $\n",
    "\n",
    "$ \\frac{∂J(B)}{∂B_j} = \\frac{1}{m} \\sum [(\\frac{1}{1+e^{-(B^Tx)}}) - y_i]x_{j,i}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e1dafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------epoch: 0------------------------------------\n",
      "\t\t\t\tcost: -0.6931471805599453\n",
      "b_dict: {'intercept': 0.003666666666666667, 'log_PFOS': 9.976846641748102e-05, 'age': 0.005614781879612744, 'gender': 0.0071261720081734915, 'BMI': 0.009237937363079844}\n",
      "------------------------------------epoch: 100------------------------------------\n",
      "\t\t\t\tcost: -0.6539572177431865\n",
      "b_dict: {'intercept': 0.13972505594387125, 'log_PFOS': 0.02367971118170717, 'age': 0.2138870505194863, 'gender': 0.2507497017915418, 'BMI': 0.3237468146185928}\n",
      "------------------------------------epoch: 200------------------------------------\n",
      "\t\t\t\tcost: -0.6522490102240123\n",
      "b_dict: {'intercept': 0.15402810805273662, 'log_PFOS': 0.03190053668344025, 'age': 0.23758336393223675, 'gender': 0.2717541566678402, 'BMI': 0.3495744796820144}\n",
      "------------------------------------epoch: 300------------------------------------\n",
      "\t\t\t\tcost: -0.6520341102384797\n",
      "b_dict: {'intercept': 0.15567719833985094, 'log_PFOS': 0.033419126194305586, 'age': 0.24068774191165113, 'gender': 0.27402078337315944, 'BMI': 0.3519518065244424}\n",
      "------------------------------------epoch: 400------------------------------------\n",
      "\t\t\t\tcost: -0.6520077339632842\n",
      "b_dict: {'intercept': 0.1558683927056963, 'log_PFOS': 0.033660037631025354, 'age': 0.24110140878865227, 'gender': 0.2742957730383899, 'BMI': 0.3521656703074247}\n",
      "------------------------------------epoch: 500------------------------------------\n",
      "\t\t\t\tcost: -0.6520047315941039\n",
      "b_dict: {'intercept': 0.1558906275003887, 'log_PFOS': 0.03369593147938927, 'age': 0.24115698780485173, 'gender': 0.27433190686716236, 'BMI': 0.35218336549295265}\n",
      "------------------------------------epoch: 600------------------------------------\n",
      "\t\t\t\tcost: -0.6520044095994778\n",
      "b_dict: {'intercept': 0.1558932338932402, 'log_PFOS': 0.03370112872648797, 'age': 0.24116452257944926, 'gender': 0.2743368958423378, 'BMI': 0.3521845462258786}\n",
      "------------------------------------epoch: 700------------------------------------\n",
      "\t\t\t\tcost: -0.6520043769144811\n",
      "b_dict: {'intercept': 0.15589354323404678, 'log_PFOS': 0.033701871608200824, 'age': 0.2411655535771261, 'gender': 0.2743376035764301, 'BMI': 0.35218457142818843}\n",
      "------------------------------------epoch: 800------------------------------------\n",
      "\t\t\t\tcost: -0.6520043738077271\n",
      "b_dict: {'intercept': 0.1558935805334856, 'log_PFOS': 0.03370197724410743, 'age': 0.2411656958902275, 'gender': 0.27433770530799595, 'BMI': 0.3521845595568883}\n",
      "------------------------------------epoch: 900------------------------------------\n",
      "\t\t\t\tcost: -0.6520043735412427\n",
      "b_dict: {'intercept': 0.15589358511315024, 'log_PFOS': 0.03370199224528735, 'age': 0.2411657156875185, 'gender': 0.2743377200125705, 'BMI': 0.35218455617605643}\n",
      "------------------------------------epoch: 999------------------------------------\n",
      "\t\t\t\tcost: -0.6520043735229346\n",
      "b_dict: {'intercept': 0.15589358568467337, 'log_PFOS': 0.03370199436974477, 'age': 0.2411657184508482, 'gender': 0.2743377221345976, 'BMI': 0.3521845555105999}\n",
      "final values: \n",
      "intercept: 0.15589359\n",
      "log_PFOS: 0.03370199\n",
      "age: 0.24116572\n",
      "gender: 0.27433772\n",
      "BMI: 0.35218456\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.1\n",
    "EPOCHS = 1000\n",
    "\n",
    "b_vector = np.zeros(X_with_intercept.shape[1]) ## initilize intercept and coefficents as 0\n",
    "cols = [\"intercept\",\"log_PFOS\", \"age\", \"gender\", \"BMI\"]\n",
    "\n",
    "\n",
    "def compute_sigmoid(B: np.ndarray, X: np.ndarray):\n",
    "\n",
    "    # return 1 / (1 + np.exp(-np.dot(X, B))) ## ALT METHOD: np.dot(X, B) computes the dot product between each row of X and B\n",
    "    return 1/(  1 + np.exp( - X @ B )  ) ## X @ B computes the dot product between each row of X and B\n",
    "\n",
    "\n",
    "def compute_cost(B: np.ndarray, X: np.ndarray, Y: np.ndarray):\n",
    "    num_rows = Y.shape[0]\n",
    "    sigmoid = compute_sigmoid(B, X)\n",
    "\n",
    "    return np.sum((Y * np.log(1/sigmoid)) + (1 - Y) * np.log(1/sigmoid)) / -num_rows\n",
    "\n",
    "def partial_derivative(B: np.ndarray, X: np.ndarray, Y: np.ndarray):\n",
    "    num_rows = Y.shape[0]\n",
    "    sigmoid = compute_sigmoid(B, X)\n",
    "\n",
    "    # return (1 / num_rows) * np.dot(X.T, (sigmoid - Y)) ## ALT METHOD\n",
    "    \n",
    "    ## (sigmoid - Y)[:,np.newaxis] changes its shape from (n,) to (n, 1)\n",
    "    return np.sum( (sigmoid - Y)[:,np.newaxis] * X, axis = 0 ) / num_rows\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    cost = compute_cost(b_vector, X_with_intercept, Y)\n",
    "    \n",
    "    b_vector -= LEARNING_RATE * partial_derivative(b_vector, X_with_intercept, Y)\n",
    "\n",
    "    b_dict = {col : b for col, b in zip(cols, b_vector)}\n",
    "\n",
    "    if epoch % 100 == 0 or epoch+1 == 1000:\n",
    "        print(f\"------------------------------------epoch: {epoch}------------------------------------\")\n",
    "        print(f\"\\t\\t\\t\\tcost: {cost}\\nb_dict: {b_dict}\")\n",
    "\n",
    "\n",
    "print(\"final values: \")\n",
    "for key, value in b_dict.items(): print(f\"{key}: {round(value,8)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4ecca7",
   "metadata": {},
   "source": [
    "(c) \n",
    "> (10 points) Apply your own algorithm to the standardized data and\n",
    "provide the values of the learned θ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9d8d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final intercept and coefficents: \n",
      "intercept: 0.15589359\n",
      "log_PFOS: 0.03370199\n",
      "age: 0.24116572\n",
      "gender: 0.27433772\n",
      "BMI: 0.35218456\n",
      "\n",
      "predicted y values:\n",
      " [-0.63768188 -0.35568051  0.28935379 -0.71980975 -0.22064997  1.35101711\n",
      " -0.93051684 -0.18920002 -0.26944778  0.31042177  0.28683218 -0.02217559\n",
      "  0.98501291  0.72088543 -0.21933665 -0.85168726  0.99216161  1.02343907\n",
      "  1.0547744  -0.26340074  0.41901037  0.22533793  0.01916788  0.2273552\n",
      " -0.87785937  0.3756261   0.6163954  -0.42789026 -0.09631984 -0.83017099\n",
      " -0.67437333 -0.50946058 -0.20149582 -0.24332532  0.12917514  0.40945855\n",
      " -0.14580022  0.90564431  0.21993656  0.39186022 -0.513669   -0.83247607\n",
      "  0.02116505 -0.12098017  0.74917571 -0.02371777  1.22138296  0.12075989\n",
      "  0.94379943  0.91592837 -0.0973883   0.45756781  0.79816807 -0.54525029\n",
      "  0.11661924  0.36770702 -0.7848109  -0.21367765 -0.16292993 -0.06461848\n",
      " -1.33210208  1.07282734  0.66071003  0.22931989  1.09987897  0.95323906\n",
      "  0.63038586  0.1478374  -0.47250965 -0.16040242  0.17313037 -0.38558247\n",
      "  0.28345648  0.31050624  0.11489547  0.03723693  0.40414212 -0.23198803\n",
      "  0.45975915 -0.02523816  0.02515332  0.02285277  1.18954332  0.55851284\n",
      " -0.01044581 -0.07554102 -0.38839247  0.09101868  1.07804278  0.3923981\n",
      "  0.76075047 -0.54622944 -0.45953298  0.33189541  0.34581671  0.83433711\n",
      " -0.34622937  0.14762242 -0.2528878  -0.01190061  0.32164787 -0.73253762\n",
      "  0.40631386  1.12338886  0.56532755  0.03671702  0.10385902  0.203031\n",
      "  0.65739128 -0.45779349 -0.11438487  0.12276238  0.60683055  0.61789225\n",
      "  0.71355867 -0.01259828  0.0672027   0.5423748   0.45675499 -0.59714638\n",
      "  0.12999966  0.18934131 -0.25474411  0.54190667 -0.79276569 -0.23434543\n",
      " -0.03344503  0.28057503  0.02357598  0.23483508  0.11493786 -1.10638867\n",
      "  0.08166648  0.18351808  0.96390434  0.44629056  0.5979862   0.39785583\n",
      "  0.73168451  0.34830113 -0.88103966  0.36841991  1.37223752  0.39932885\n",
      "  0.16439623  0.52601897  0.63293915  1.05118415 -0.15536911 -0.15544723\n",
      "  0.93442894  0.50801713 -0.04939386 -0.19256889 -0.50973961 -0.17957294\n",
      "  1.25313745  0.37347652  0.43158539 -0.09601531  0.15668874 -0.20265112\n",
      "  0.13327929  0.77753185  0.11492549 -0.95305414  0.35734573  0.66201233\n",
      "  0.78595569 -0.18374611  0.26041429  0.97714959  0.31028527  0.51515328\n",
      " -0.32771215 -0.29937618  0.28004395 -0.21432633  0.18993047 -0.39206014\n",
      "  0.03417555  0.048127    1.13422195  0.4146705   0.9734729  -1.21433739\n",
      "  0.39868695 -0.34924947  0.41077697  0.48472657  0.08603021 -0.03691372\n",
      "  0.61245296  0.20194976 -0.2911846   0.05214345 -0.40290496 -0.28636934\n",
      "  0.33615371  0.66648273  0.80604631  0.15656615  0.26939971  0.1912158\n",
      "  0.11747364  0.12182425  0.26778813  0.92495369 -0.45696129 -0.15575269\n",
      " -0.76998365  0.11714688 -0.80020996 -0.80836086  0.62375721 -0.50609561\n",
      "  0.62708554  0.25896442  0.65601014 -0.49708265 -0.16693851  0.87920461\n",
      "  0.37239538  0.07269219  0.33859643 -0.80462048  0.0378708  -0.09616564\n",
      "  0.41131055 -0.57125393  0.11002922 -0.08884893  0.0895127  -0.26665167\n",
      "  0.6103932  -0.29724014 -0.71740675 -0.18198057 -0.52538575  0.0276432\n",
      "  0.21084878 -0.31137827  0.45563353  0.34176252  0.43315712  0.90499261\n",
      "  1.15653412  0.56517371  0.02918124 -0.64989134  1.27609278 -0.13340067\n",
      "  0.24356705  0.2378645  -0.56058259  0.97369887  0.36003246  0.57856185\n",
      "  0.71981204  1.29379748  0.45964836  0.27838328 -0.46132819  0.29559786\n",
      "  0.71353416  0.70533027  0.55733764  0.15413819  0.0986567  -0.05644851\n",
      "  0.06065792 -0.55454891  0.15537065  0.65988252  0.5173583  -0.6447234\n",
      "  0.45771163 -0.18758105  0.18166622 -0.09073831  0.70040346 -0.33121437\n",
      " -0.5877637   0.50654326  0.88785256 -0.5347571   0.23896499  1.35862457\n",
      " -0.28862916  0.28728024 -0.63442013  0.51992022  0.00648195 -0.2527194\n",
      " -0.83431113  0.31191916  0.39749817  0.52919018  0.72998193  0.18709357]\n"
     ]
    }
   ],
   "source": [
    "## for each row (sample) in x, multiply the variables (x1-x4) by the weights in b\n",
    "## sum the resulting vector \n",
    "## this is the dot product \n",
    "\n",
    "print(\"final intercept and coefficents: \")\n",
    "for key, value in b_dict.items(): print(f\"{key}: {round(value,8)}\")\n",
    "\n",
    "y_predicted = np.dot( X_with_intercept, b_vector )\n",
    "# y_predicted = np.dot( X, b_vector[1: len(b_vector)] ) + b_vector[0] ## b_vector[0] is the intercept\n",
    "\n",
    "print(\"\\npredicted y values:\\n\", y_predicted )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "6e32b412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = np.where(y_predicted > 0, 1, 0) - Y\n",
    "len(diff[diff > 0]) / 300 ## 78 missclassified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061425f7",
   "metadata": {},
   "source": [
    "### Sklearn\n",
    "\n",
    "(d) \n",
    "> (10 points) Apply LogisticRegression in sklearn to the y and the stan-\n",
    "dardized x. What are the θ values you get from sklearn? Information\n",
    "about how to apply LogisticRegression in sklear can be found at\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.\n",
    "linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9485ded2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficent: {'log_PFOS': 0.033675373184102304, 'age': 0.24156794428388667, 'gender': 0.27431454819455997, 'BMI': 0.35239964201490753}\n",
      "intercept: [0.1560249]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_df = df.loc[:,[\"log_PFOS\", \"age\", \"gender\", \"BMI\"]]\n",
    "\n",
    "Y_df = df[\"disease\"]\n",
    "\n",
    "\n",
    "logreg = LogisticRegression(random_state=16,  max_iter=1000, penalty=None)\n",
    "\n",
    "model = logreg.fit(X_df, Y_df)\n",
    "coef_df = {col : coef for col, coef in zip(list(cols[1:len(cols)]), model.coef_[0])}\n",
    "# print(coef_df)\n",
    "# print(X.columns)\n",
    "print(f\"coefficent: {coef_df}\\nintercept: {model.intercept_}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab0e1bf",
   "metadata": {},
   "source": [
    "### statsmodel\n",
    "(e) \n",
    "> (10 points) Add constant to the standardized x using the function\n",
    "add constant. Instructions about how to use add constant can be\n",
    "found at:\n",
    "https://www.statsmodels.org/dev/generated/statsmodels.tools.tools.add_constant.html\n",
    "Apply Logit in statsmodels to the data with constant 1 added. What\n",
    "θ do you get? Instructions about how to use statsmodels to do logistic\n",
    "regression can be found at:\n",
    "https://www.statsmodels.org/stable/generated/statsmodels.formula.api.logit.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "11e0304f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.658576\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>disease</td>     <th>  No. Observations:  </th>  <td>   300</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   295</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     4</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sun, 28 Sep 2025</td> <th>  Pseudo R-squ.:     </th>  <td>0.04617</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>12:49:18</td>     <th>  Log-Likelihood:    </th> <td> -197.57</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -207.14</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>0.0007418</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.1559</td> <td>    0.120</td> <td>    1.303</td> <td> 0.193</td> <td>   -0.079</td> <td>    0.390</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_PFOS</th>  <td>    0.0337</td> <td>    0.121</td> <td>    0.280</td> <td> 0.780</td> <td>   -0.203</td> <td>    0.270</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>       <td>    0.2412</td> <td>    0.123</td> <td>    1.963</td> <td> 0.050</td> <td>    0.000</td> <td>    0.482</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender</th>    <td>    0.2743</td> <td>    0.120</td> <td>    2.280</td> <td> 0.023</td> <td>    0.038</td> <td>    0.510</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BMI</th>       <td>    0.3522</td> <td>    0.123</td> <td>    2.868</td> <td> 0.004</td> <td>    0.112</td> <td>    0.593</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}   &     disease      & \\textbf{  No. Observations:  } &      300    \\\\\n",
       "\\textbf{Model:}           &      Logit       & \\textbf{  Df Residuals:      } &      295    \\\\\n",
       "\\textbf{Method:}          &       MLE        & \\textbf{  Df Model:          } &        4    \\\\\n",
       "\\textbf{Date:}            & Sun, 28 Sep 2025 & \\textbf{  Pseudo R-squ.:     } &  0.04617    \\\\\n",
       "\\textbf{Time:}            &     12:49:18     & \\textbf{  Log-Likelihood:    } &   -197.57   \\\\\n",
       "\\textbf{converged:}       &       True       & \\textbf{  LL-Null:           } &   -207.14   \\\\\n",
       "\\textbf{Covariance Type:} &    nonrobust     & \\textbf{  LLR p-value:       } & 0.0007418   \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &       0.1559  &        0.120     &     1.303  &         0.193        &       -0.079    &        0.390     \\\\\n",
       "\\textbf{log\\_PFOS} &       0.0337  &        0.121     &     0.280  &         0.780        &       -0.203    &        0.270     \\\\\n",
       "\\textbf{age}       &       0.2412  &        0.123     &     1.963  &         0.050        &        0.000    &        0.482     \\\\\n",
       "\\textbf{gender}    &       0.2743  &        0.120     &     2.280  &         0.023        &        0.038    &        0.510     \\\\\n",
       "\\textbf{BMI}       &       0.3522  &        0.123     &     2.868  &         0.004        &        0.112    &        0.593     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Logit Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                disease   No. Observations:                  300\n",
       "Model:                          Logit   Df Residuals:                      295\n",
       "Method:                           MLE   Df Model:                            4\n",
       "Date:                Sun, 28 Sep 2025   Pseudo R-squ.:                 0.04617\n",
       "Time:                        12:49:18   Log-Likelihood:                -197.57\n",
       "converged:                       True   LL-Null:                       -207.14\n",
       "Covariance Type:            nonrobust   LLR p-value:                 0.0007418\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.1559      0.120      1.303      0.193      -0.079       0.390\n",
       "log_PFOS       0.0337      0.121      0.280      0.780      -0.203       0.270\n",
       "age            0.2412      0.123      1.963      0.050       0.000       0.482\n",
       "gender         0.2743      0.120      2.280      0.023       0.038       0.510\n",
       "BMI            0.3522      0.123      2.868      0.004       0.112       0.593\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df_with_intercept = statsmodels.tools.tools.add_constant(X_df, prepend=True)\n",
    "model = api.logit(formula=\"disease ~ log_PFOS + age + gender + BMI\", data = pd.concat([X_df_with_intercept, Y_df], axis = 1))\n",
    "\n",
    "model.fit().summary()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
