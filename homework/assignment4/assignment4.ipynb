{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d808aafd",
   "metadata": {},
   "source": [
    "# 1. Logistic Regression\n",
    "\n",
    "(a) \n",
    "> (10 points) Do natural log transform of the PFOS variable in file\n",
    "pfas.csv and store the results as a new variable log PFOS in the\n",
    "data file. Standardize the variables x=[log PFOS, age, gender, BMI]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "740fb93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brean\\AppData\\Local\\Temp\\ipykernel_28160\\3504629728.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.formula.api as api\n",
    "import statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84aecb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoscale(df, variables_to_scale):\n",
    "    \"\"\"standardizes variables\"\"\"\n",
    "    for variable in variables_to_scale:\n",
    "        df[variable] = ( df[variable] - np.mean(df[variable]) ) / np.std(df[variable])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a6b566f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disease\n",
      " [0 0 0 0 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0 1 0 1 1 0 0 1 0 1 0 0 0 0 1 0 1\n",
      " 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 0 0 1 1 0 1 1 0 0\n",
      " 0 1 1 1 1 1 1 0 1 0 0 1 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 1 1 1 0 0 1 1 1 0\n",
      " 0 1 0 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0 0 1 1 0 1 0 1 1\n",
      " 0 1 1 0 1 0 0 0 1 0 1 1 0 1 0 1 0 0 1 1 0 0 1 1 0 1 0 1 0 0 1 0 1 1 0 1 1\n",
      " 0 1 1 1 1 0 0 0 0 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 1 0 0 0 1 1 0 1 0 1 1\n",
      " 1 1 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 1 0 1 1 0 0 0 1 1 0 0\n",
      " 1 1 0 0 1 0 0 0 0 1 0 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1\n",
      " 0 0 1 0]\n",
      "     intercept|    age   |   gender     |  BMI    |    log_PFOS\n",
      " [[ 1.         -1.06321047 -1.06191317 -0.78453458  0.90375231]\n",
      " [ 1.          0.96375408 -1.06191317 -1.18985472 -0.99778188]\n",
      " [ 1.          0.31512542  0.94169658 -0.5470809  -0.24350772]\n",
      " ...\n",
      " [ 1.          0.396204    0.94169658  0.07829738 -0.24248557]\n",
      " [ 1.          0.15296826  0.94169658  0.8139823  -0.23195204]\n",
      " [ 1.          0.80159691 -1.06191317  0.33858428  0.29556023]]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"pfas.csv\")\n",
    "df[\"log_PFOS\"] = np.log(df[\"PFOS\"])\n",
    "\n",
    "autoscale(df, [\"age\", \"gender\", \"BMI\", \"log_PFOS\"])\n",
    "\n",
    "#### Initalize variables\n",
    "Y = df[\"disease\"].to_numpy()\n",
    "X = df.loc[:,[\"age\", \"gender\", \"BMI\", \"log_PFOS\"]].to_numpy()\n",
    "## add intercept\n",
    "X_with_intercept = np.insert( X, 0, np.array([1]*X.shape[0]), axis = 1 )\n",
    "\n",
    "\n",
    "print(\"disease\\n\", Y)\n",
    "print(\"     intercept|    age   |   gender     |  BMI    |    log_PFOS\\n\",X_with_intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40e3534",
   "metadata": {},
   "source": [
    "#### Initalize variables using StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "e1f19145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disease\n",
      " [0 0 0 0 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0 1 0 1 1 0 0 1 0 1 0 0 0 0 1 0 1\n",
      " 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 0 0 1 1 0 1 1 0 0\n",
      " 0 1 1 1 1 1 1 0 1 0 0 1 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 1 1 1 0 0 1 1 1 0\n",
      " 0 1 0 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0 0 1 1 0 1 0 1 1\n",
      " 0 1 1 0 1 0 0 0 1 0 1 1 0 1 0 1 0 0 1 1 0 0 1 1 0 1 0 1 0 0 1 0 1 1 0 1 1\n",
      " 0 1 1 1 1 0 0 0 0 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 1 0 0 0 1 1 0 1 0 1 1\n",
      " 1 1 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 1 0 1 1 0 0 0 1 1 0 0\n",
      " 1 1 0 0 1 0 0 0 0 1 0 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1\n",
      " 0 0 1 0]\n",
      "     intercept|    age   |   gender     |  BMI    |    log_PFOS\n",
      " [[ 1.         -1.06321047 -1.06191317 -0.78453458  0.90375231]\n",
      " [ 1.          0.96375408 -1.06191317 -1.18985472 -0.99778188]\n",
      " [ 1.          0.31512542  0.94169658 -0.5470809  -0.24350772]\n",
      " ...\n",
      " [ 1.          0.396204    0.94169658  0.07829738 -0.24248557]\n",
      " [ 1.          0.15296826  0.94169658  0.8139823  -0.23195204]\n",
      " [ 1.          0.80159691 -1.06191317  0.33858428  0.29556023]]\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"pfas.csv\")\n",
    "df2[\"log_PFOS\"] = np.log2(df2[\"PFOS\"])\n",
    "\n",
    "# StandardScaler().fit(df2[[\"log_PFOS\", \"age\", \"gender\", \"BMI\"]])\n",
    "X = StandardScaler().fit_transform(df2[[\"age\", \"gender\", \"BMI\", \"log_PFOS\"]])\n",
    "X_with_intercept2 = np.insert( X, 0, np.array([1]*X.shape[0]), axis = 1 )\n",
    "\n",
    "Y = df[\"disease\"].to_numpy()\n",
    "\n",
    "print(\"disease\\n\", Y)\n",
    "print(\"     intercept|    age   |   gender     |  BMI    |    log_PFOS\\n\",X_with_intercept2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "5954c47b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "False in (X_with_intercept == X_with_intercept2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5ccfa6",
   "metadata": {},
   "source": [
    "### Numerical Solution\n",
    "(b) \n",
    "> (35 points) Use y=disease and the standardized x=[PFOS, age,\n",
    "gender, BMI] to write and debug your own gradient descent algorithm for logistic regression. Your algorithm should export the\n",
    "learned parameters in the θ vector. Note that you can modify the\n",
    "gradient descent algorithm that you have written for the linear regression algorithm to achieve logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373675a3",
   "metadata": {},
   "source": [
    "#### Sigmoid\n",
    "\n",
    "$ g(B^Tx)= \\frac{1}{1+e^{-(B^Tx)}}$\n",
    "\n",
    "$B^Tx=B_0x_0+B_1x_1+...+B_nx_n$\n",
    "\n",
    "$x_0=1$\n",
    "\n",
    "\n",
    "$$\n",
    "y = \\begin{cases}\n",
    "    \\text{1 if} & B^Tx\\text{ ≥ 0} \\\\\n",
    "    \\text{0 if} & B^Tx\\text{< 0} \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "\n",
    "#### Cost Function\n",
    "\n",
    "$i$ is a row $j$ is a column\n",
    "\n",
    "$ J(B) = -\\frac{1}{m} \\sum_{i=1}^m [y_i ln(\\frac{1}{1+e^{-(B^Tx)}}) + (1-y_i)ln(\\frac{1}{1+e^{-(B^Tx)}})]$\n",
    "\n",
    "$ B_j := B_j-α(\\frac{∂J(B)}{∂B_j}) $\n",
    "\n",
    "$ \\frac{∂J(B)}{∂B_j} = \\frac{1}{m} \\sum [(\\frac{1}{1+e^{-(B^Tx)}}) - y_i]x_{j,i}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81e1dafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------epoch: 0------------------------------------\n",
      "\t\t\t\tcost: 0.6931471805599453\n",
      "b_dict: {'intercept': 0.003666666666666667, 'log_PFOS': 0.005614781879612744, 'age': 0.0071261720081734915, 'gender': 0.009237937363079844, 'BMI': 9.976846641748035e-05}\n",
      "------------------------------------epoch: 100------------------------------------\n",
      "\t\t\t\tcost: 0.6539572177431865\n",
      "b_dict: {'intercept': 0.13972505594387125, 'log_PFOS': 0.21388705051948634, 'age': 0.2507497017915419, 'gender': 0.3237468146185928, 'BMI': 0.023679711181707166}\n",
      "------------------------------------epoch: 200------------------------------------\n",
      "\t\t\t\tcost: 0.6522490102240123\n",
      "b_dict: {'intercept': 0.15402810805273662, 'log_PFOS': 0.23758336393223678, 'age': 0.2717541566678402, 'gender': 0.34957447968201444, 'BMI': 0.031900536683440256}\n",
      "------------------------------------epoch: 300------------------------------------\n",
      "\t\t\t\tcost: 0.6520341102384797\n",
      "b_dict: {'intercept': 0.15567719833985094, 'log_PFOS': 0.24068774191165115, 'age': 0.27402078337315944, 'gender': 0.3519518065244424, 'BMI': 0.033419126194305586}\n",
      "------------------------------------epoch: 400------------------------------------\n",
      "\t\t\t\tcost: 0.6520077339632842\n",
      "b_dict: {'intercept': 0.1558683927056963, 'log_PFOS': 0.24110140878865227, 'age': 0.2742957730383899, 'gender': 0.3521656703074247, 'BMI': 0.03366003763102537}\n",
      "------------------------------------epoch: 500------------------------------------\n",
      "\t\t\t\tcost: 0.6520047315941039\n",
      "b_dict: {'intercept': 0.1558906275003887, 'log_PFOS': 0.24115698780485173, 'age': 0.2743319068671623, 'gender': 0.35218336549295265, 'BMI': 0.03369593147938928}\n",
      "------------------------------------epoch: 600------------------------------------\n",
      "\t\t\t\tcost: 0.6520044095994778\n",
      "b_dict: {'intercept': 0.15589323389324022, 'log_PFOS': 0.24116452257944926, 'age': 0.2743368958423378, 'gender': 0.35218454622587864, 'BMI': 0.03370112872648798}\n",
      "------------------------------------epoch: 700------------------------------------\n",
      "\t\t\t\tcost: 0.6520043769144811\n",
      "b_dict: {'intercept': 0.1558935432340468, 'log_PFOS': 0.24116555357712607, 'age': 0.2743376035764301, 'gender': 0.35218457142818843, 'BMI': 0.03370187160820085}\n",
      "------------------------------------epoch: 800------------------------------------\n",
      "\t\t\t\tcost: 0.6520043738077271\n",
      "b_dict: {'intercept': 0.1558935805334856, 'log_PFOS': 0.2411656958902275, 'age': 0.27433770530799595, 'gender': 0.3521845595568883, 'BMI': 0.03370197724410745}\n",
      "------------------------------------epoch: 900------------------------------------\n",
      "\t\t\t\tcost: 0.6520043735412427\n",
      "b_dict: {'intercept': 0.15589358511315027, 'log_PFOS': 0.2411657156875185, 'age': 0.2743377200125705, 'gender': 0.35218455617605643, 'BMI': 0.03370199224528736}\n",
      "------------------------------------epoch: 999------------------------------------\n",
      "\t\t\t\tcost: 0.6520043735229346\n",
      "b_dict: {'intercept': 0.15589358568467337, 'log_PFOS': 0.2411657184508482, 'age': 0.2743377221345976, 'gender': 0.3521845555105999, 'BMI': 0.033701994369744775}\n",
      "final values: \n",
      "intercept: 0.15589359\n",
      "log_PFOS: 0.24116572\n",
      "age: 0.27433772\n",
      "gender: 0.35218456\n",
      "BMI: 0.03370199\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.1\n",
    "EPOCHS = 1000\n",
    "\n",
    "b_vector = np.zeros(X_with_intercept.shape[1]) ## initilize intercept and coefficents as 0\n",
    "cols = [\"intercept\",\"log_PFOS\", \"age\", \"gender\", \"BMI\"]\n",
    "\n",
    "\n",
    "def compute_sigmoid(B: np.ndarray, X: np.ndarray):\n",
    "\n",
    "    # return 1 / (1 + np.exp(-np.dot(X, B))) ## ALT METHOD: np.dot(X, B) computes the dot product between each row of X and B\n",
    "    return 1/(  1 + np.exp( - X @ B )  ) ## X @ B computes the dot product between each row of X and B\n",
    "\n",
    "\n",
    "def compute_cost(B: np.ndarray, X: np.ndarray, Y: np.ndarray):\n",
    "    num_rows = Y.shape[0]\n",
    "    sigmoid = compute_sigmoid(B, X)\n",
    "\n",
    "    return np.sum((Y * np.log(sigmoid)) + (1 - Y) * np.log(sigmoid)) / -num_rows\n",
    "\n",
    "def partial_derivative(B: np.ndarray, X: np.ndarray, Y: np.ndarray):\n",
    "    num_rows = Y.shape[0]\n",
    "    sigmoid = compute_sigmoid(B, X)\n",
    "\n",
    "    # return (1 / num_rows) * np.dot(X.T, (sigmoid - Y)) ## ALT METHOD\n",
    "    \n",
    "    ## (sigmoid - Y)[:,np.newaxis] changes its shape from (n,) to (n, 1)\n",
    "    return np.sum( (sigmoid - Y)[:,np.newaxis] * X, axis = 0 ) / num_rows\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    cost = compute_cost(b_vector, X_with_intercept, Y)\n",
    "    \n",
    "    b_vector -= LEARNING_RATE * partial_derivative(b_vector, X_with_intercept, Y)\n",
    "\n",
    "    b_dict = {col : b for col, b in zip(cols, b_vector)}\n",
    "\n",
    "    if epoch % 100 == 0 or epoch+1 == 1000:\n",
    "        print(f\"------------------------------------epoch: {epoch}------------------------------------\")\n",
    "        print(f\"\\t\\t\\t\\tcost: {cost}\\nb_dict: {b_dict}\")\n",
    "\n",
    "\n",
    "print(\"final values: \")\n",
    "for key, value in b_dict.items(): print(f\"{key}: {round(value,8)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4ecca7",
   "metadata": {},
   "source": [
    "(c) \n",
    "> (10 points) Apply your own algorithm to the standardized data and\n",
    "provide the values of the learned θ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9d8d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final intercept and coefficents: \n",
      "intercept: 0.15589359\n",
      "log_PFOS: 0.24116572\n",
      "age: 0.27433772\n",
      "gender: 0.35218456\n",
      "BMI: 0.03370199\n",
      "\n",
      "predicted y values:\n",
      " [-0.63768188 -0.35568051  0.28935379 -0.71980975 -0.22064997  1.35101711\n",
      " -0.93051684 -0.18920002 -0.26944778  0.31042177  0.28683218 -0.02217559\n",
      "  0.98501291  0.72088543 -0.21933665 -0.85168726  0.99216161  1.02343907\n",
      "  1.0547744  -0.26340074  0.41901037  0.22533793  0.01916788  0.2273552\n",
      " -0.87785937  0.3756261   0.6163954  -0.42789026 -0.09631984 -0.83017099\n",
      " -0.67437333 -0.50946058 -0.20149582 -0.24332532  0.12917514  0.40945855\n",
      " -0.14580022  0.90564431  0.21993656  0.39186022 -0.513669   -0.83247607\n",
      "  0.02116505 -0.12098017  0.74917571 -0.02371777  1.22138296  0.12075989\n",
      "  0.94379943  0.91592837 -0.0973883   0.45756781  0.79816807 -0.54525029\n",
      "  0.11661924  0.36770702 -0.7848109  -0.21367765 -0.16292993 -0.06461848\n",
      " -1.33210208  1.07282734  0.66071003  0.22931989  1.09987897  0.95323906\n",
      "  0.63038586  0.1478374  -0.47250965 -0.16040242  0.17313037 -0.38558247\n",
      "  0.28345648  0.31050624  0.11489547  0.03723693  0.40414212 -0.23198803\n",
      "  0.45975915 -0.02523816  0.02515332  0.02285277  1.18954332  0.55851284\n",
      " -0.01044581 -0.07554102 -0.38839247  0.09101868  1.07804278  0.3923981\n",
      "  0.76075047 -0.54622944 -0.45953298  0.33189541  0.34581671  0.83433711\n",
      " -0.34622937  0.14762242 -0.2528878  -0.01190061  0.32164787 -0.73253762\n",
      "  0.40631386  1.12338886  0.56532755  0.03671702  0.10385902  0.203031\n",
      "  0.65739128 -0.45779349 -0.11438487  0.12276238  0.60683055  0.61789225\n",
      "  0.71355867 -0.01259828  0.0672027   0.5423748   0.45675499 -0.59714638\n",
      "  0.12999966  0.18934131 -0.25474411  0.54190667 -0.79276569 -0.23434543\n",
      " -0.03344503  0.28057503  0.02357598  0.23483508  0.11493786 -1.10638867\n",
      "  0.08166648  0.18351808  0.96390434  0.44629056  0.5979862   0.39785583\n",
      "  0.73168451  0.34830113 -0.88103966  0.36841991  1.37223752  0.39932885\n",
      "  0.16439623  0.52601897  0.63293915  1.05118415 -0.15536911 -0.15544723\n",
      "  0.93442894  0.50801713 -0.04939386 -0.19256889 -0.50973961 -0.17957294\n",
      "  1.25313745  0.37347652  0.43158539 -0.09601531  0.15668874 -0.20265112\n",
      "  0.13327929  0.77753185  0.11492549 -0.95305414  0.35734573  0.66201233\n",
      "  0.78595569 -0.18374611  0.26041429  0.97714959  0.31028527  0.51515328\n",
      " -0.32771215 -0.29937618  0.28004395 -0.21432633  0.18993047 -0.39206014\n",
      "  0.03417555  0.048127    1.13422195  0.4146705   0.9734729  -1.21433739\n",
      "  0.39868695 -0.34924947  0.41077697  0.48472657  0.08603021 -0.03691372\n",
      "  0.61245296  0.20194976 -0.2911846   0.05214345 -0.40290496 -0.28636934\n",
      "  0.33615371  0.66648273  0.80604631  0.15656615  0.26939971  0.1912158\n",
      "  0.11747364  0.12182425  0.26778813  0.92495369 -0.45696129 -0.15575269\n",
      " -0.76998365  0.11714688 -0.80020996 -0.80836086  0.62375721 -0.50609561\n",
      "  0.62708554  0.25896442  0.65601014 -0.49708265 -0.16693851  0.87920461\n",
      "  0.37239538  0.07269219  0.33859643 -0.80462048  0.0378708  -0.09616564\n",
      "  0.41131055 -0.57125393  0.11002922 -0.08884893  0.0895127  -0.26665167\n",
      "  0.6103932  -0.29724014 -0.71740675 -0.18198057 -0.52538575  0.0276432\n",
      "  0.21084878 -0.31137827  0.45563353  0.34176252  0.43315712  0.90499261\n",
      "  1.15653412  0.56517371  0.02918124 -0.64989134  1.27609278 -0.13340067\n",
      "  0.24356705  0.2378645  -0.56058259  0.97369887  0.36003246  0.57856185\n",
      "  0.71981204  1.29379748  0.45964836  0.27838328 -0.46132819  0.29559786\n",
      "  0.71353416  0.70533027  0.55733764  0.15413819  0.0986567  -0.05644851\n",
      "  0.06065792 -0.55454891  0.15537065  0.65988252  0.5173583  -0.6447234\n",
      "  0.45771163 -0.18758105  0.18166622 -0.09073831  0.70040346 -0.33121437\n",
      " -0.5877637   0.50654326  0.88785256 -0.5347571   0.23896499  1.35862457\n",
      " -0.28862916  0.28728024 -0.63442013  0.51992022  0.00648195 -0.2527194\n",
      " -0.83431113  0.31191916  0.39749817  0.52919018  0.72998193  0.18709357]\n"
     ]
    }
   ],
   "source": [
    "## for each row (sample) in x, multiply the variables (x1-x4) by the weights in b\n",
    "## sum the resulting vector \n",
    "## this is the dot product \n",
    "\n",
    "print(\"final intercept and coefficents: \")\n",
    "for key, value in b_dict.items(): print(f\"{key}: {round(value,8)}\")\n",
    "\n",
    "y_predicted = np.dot( X_with_intercept, b_vector )\n",
    "# y_predicted = np.dot( X, b_vector[1: len(b_vector)] ) + b_vector[0] ## b_vector[0] is the intercept\n",
    "\n",
    "print(\"\\npredicted y values:\\n\", y_predicted )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "6e32b412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = np.where(y_predicted > 0, 1, 0) - Y\n",
    "len(diff[diff > 0]) / 300 ## 78 missclassified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061425f7",
   "metadata": {},
   "source": [
    "### Sklearn\n",
    "\n",
    "(d) \n",
    "> (10 points) Apply LogisticRegression in sklearn to the y and the stan-\n",
    "dardized x. What are the θ values you get from sklearn? Information\n",
    "about how to apply LogisticRegression in sklear can be found at\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.\n",
    "linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9485ded2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficent: {'log_PFOS': 0.2415679442838867, 'age': 0.27431454819456, 'gender': 0.3523996420149074, 'BMI': 0.033675373184102346}\n",
      "intercept: [0.1560249]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logreg = LogisticRegression(random_state=16,  max_iter=1000, penalty=None)\n",
    "\n",
    "# model = logreg.fit(X_df, Y_df)\n",
    "SklearnModel = logreg.fit(X, Y)\n",
    "\n",
    "coef_df = {col : coef for col, coef in zip(list(cols[1:len(cols)]), SklearnModel.coef_[0])}\n",
    "# print(coef_df)\n",
    "# print(X.columns)\n",
    "print(f\"coefficent: {coef_df}\\nintercept: {SklearnModel.intercept_}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab0e1bf",
   "metadata": {},
   "source": [
    "### statsmodel\n",
    "(e) \n",
    "> (10 points) Add constant to the standardized x using the function\n",
    "add constant. Instructions about how to use add constant can be\n",
    "found at:\n",
    "https://www.statsmodels.org/dev/generated/statsmodels.tools.tools.add_constant.html\n",
    "Apply Logit in statsmodels to the data with constant 1 added. What\n",
    "θ do you get? Instructions about how to use statsmodels to do logistic\n",
    "regression can be found at:\n",
    "https://www.statsmodels.org/stable/generated/statsmodels.formula.api.logit.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11e0304f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.658576\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>disease</td>     <th>  No. Observations:  </th>  <td>   300</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   295</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     4</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 02 Oct 2025</td> <th>  Pseudo R-squ.:     </th>  <td>0.04617</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>18:09:06</td>     <th>  Log-Likelihood:    </th> <td> -197.57</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -207.14</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>0.0007418</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.1559</td> <td>    0.120</td> <td>    1.303</td> <td> 0.193</td> <td>   -0.079</td> <td>    0.390</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>       <td>    0.2412</td> <td>    0.123</td> <td>    1.963</td> <td> 0.050</td> <td>    0.000</td> <td>    0.482</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender</th>    <td>    0.2743</td> <td>    0.120</td> <td>    2.280</td> <td> 0.023</td> <td>    0.038</td> <td>    0.510</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BMI</th>       <td>    0.3522</td> <td>    0.123</td> <td>    2.868</td> <td> 0.004</td> <td>    0.112</td> <td>    0.593</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_PFOS</th>  <td>    0.0337</td> <td>    0.121</td> <td>    0.280</td> <td> 0.780</td> <td>   -0.203</td> <td>    0.270</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}   &     disease      & \\textbf{  No. Observations:  } &      300    \\\\\n",
       "\\textbf{Model:}           &      Logit       & \\textbf{  Df Residuals:      } &      295    \\\\\n",
       "\\textbf{Method:}          &       MLE        & \\textbf{  Df Model:          } &        4    \\\\\n",
       "\\textbf{Date:}            & Thu, 02 Oct 2025 & \\textbf{  Pseudo R-squ.:     } &  0.04617    \\\\\n",
       "\\textbf{Time:}            &     18:09:06     & \\textbf{  Log-Likelihood:    } &   -197.57   \\\\\n",
       "\\textbf{converged:}       &       True       & \\textbf{  LL-Null:           } &   -207.14   \\\\\n",
       "\\textbf{Covariance Type:} &    nonrobust     & \\textbf{  LLR p-value:       } & 0.0007418   \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &       0.1559  &        0.120     &     1.303  &         0.193        &       -0.079    &        0.390     \\\\\n",
       "\\textbf{age}       &       0.2412  &        0.123     &     1.963  &         0.050        &        0.000    &        0.482     \\\\\n",
       "\\textbf{gender}    &       0.2743  &        0.120     &     2.280  &         0.023        &        0.038    &        0.510     \\\\\n",
       "\\textbf{BMI}       &       0.3522  &        0.123     &     2.868  &         0.004        &        0.112    &        0.593     \\\\\n",
       "\\textbf{log\\_PFOS} &       0.0337  &        0.121     &     0.280  &         0.780        &       -0.203    &        0.270     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Logit Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                disease   No. Observations:                  300\n",
       "Model:                          Logit   Df Residuals:                      295\n",
       "Method:                           MLE   Df Model:                            4\n",
       "Date:                Thu, 02 Oct 2025   Pseudo R-squ.:                 0.04617\n",
       "Time:                        18:09:06   Log-Likelihood:                -197.57\n",
       "converged:                       True   LL-Null:                       -207.14\n",
       "Covariance Type:            nonrobust   LLR p-value:                 0.0007418\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.1559      0.120      1.303      0.193      -0.079       0.390\n",
       "age            0.2412      0.123      1.963      0.050       0.000       0.482\n",
       "gender         0.2743      0.120      2.280      0.023       0.038       0.510\n",
       "BMI            0.3522      0.123      2.868      0.004       0.112       0.593\n",
       "log_PFOS       0.0337      0.121      0.280      0.780      -0.203       0.270\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df = df.loc[:,[\"age\", \"gender\", \"BMI\", \"log_PFOS\"]]\n",
    "\n",
    "Y_df = df[\"disease\"]\n",
    "\n",
    "X_df_with_intercept = statsmodels.tools.tools.add_constant(X_df, prepend=True)\n",
    "model = api.logit(formula=\"disease ~ age + gender + BMI + log_PFOS\", data = pd.concat([X_df_with_intercept, Y_df], axis = 1))\n",
    "\n",
    "model.fit().summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d107ddd",
   "metadata": {},
   "source": [
    "> (f) (25 points) Compare θ from your own algorithm, θ from LogisticRe-\n",
    "gression in sklearn, and θ from statsmodel. Do you get very similar\n",
    "results? If not, what could you do to make the θ values similar?\n",
    "\n",
    "Below are the coefficents and intercepts for all of the models. \n",
    "\n",
    "**My final intercept and coefficents:**\n",
    "|Coefficent   | Value  |\n",
    "|-------------|--------|\n",
    "|intercept    |0.155894|\n",
    "|log_PFOS     |0.241166|\n",
    "|age          |0.274338|\n",
    "|gender       |0.352185|\n",
    "|BMI          |0.033702|\n",
    "-----------------------------------------------------------------\n",
    "**Sklearn intercept and coefficents:**\n",
    "|Coefficent   | Value  |\n",
    "|-------------|--------|\n",
    "|intercept    |0.156025|\n",
    "|log_PFOS     |0.241568|\n",
    "|age          |0.274315|\n",
    "|gender       |0.3524  |\n",
    "|BMI          |0.033675|\n",
    "-----------------------------------------------------------------\n",
    "**StatsModel intercept and coefficents:**\n",
    "|Coefficent   | Value  |\n",
    "|-------------|--------|\n",
    "|Intercept    |0.155894|\n",
    "|age          |0.241166|\n",
    "|gender       |0.274338|\n",
    "|BMI          |0.352185|\n",
    "|log_PFOS     |0.033702|\n",
    "\n",
    "The coefficents from sklearn and statsmodel were practically the same as my values which means "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129424e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My final intercept and coefficents: \n",
      "intercept: 0.155894\n",
      "log_PFOS: 0.241166\n",
      "age: 0.274338\n",
      "gender: 0.352185\n",
      "BMI: 0.033702\n",
      "-----------------------------------------------------------------\n",
      "Sklearn intercept and coefficents\n",
      "intercept: 0.156025\n",
      "log_PFOS: 0.241568\n",
      "age: 0.274315\n",
      "gender: 0.3524\n",
      "BMI: 0.033675\n",
      "-----------------------------------------------------------------\n",
      "StatsModel intercept and coefficents\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.658576\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Intercept    0.155894\n",
       "age          0.241166\n",
       "gender       0.274338\n",
       "BMI          0.352185\n",
       "log_PFOS     0.033702\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"My final intercept and coefficents:\")\n",
    "for key, value in b_dict.items(): print(f\"{key}: {round(value, 6)}\")\n",
    "\n",
    "print(\"-----------------------------------------------------------------\")\n",
    "print(\"Sklearn intercept and coefficents:\")\n",
    "print(f\"intercept: {round(SklearnModel.intercept_[0], 6)}\")\n",
    "for key, value in coef_df.items(): print(f\"{key}: {round(value, 6)}\")\n",
    "print(\"-----------------------------------------------------------------\")\n",
    "print(\"StatsModel intercept and coefficents:\\n\")\n",
    "model.fit().params\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
