{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f425d8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "96add420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Linear(num_nodes_input_layer, num_nodes_output_layer):\n",
    "    \"\"\"Dimensions: output is rows, input is columns.\"\"\"\n",
    "    seed(1)\n",
    "    weights = np.random.rand(num_nodes_output_layer, num_nodes_input_layer + 1)\n",
    "    # biases = np.ones((weights.shape[0], 1))\n",
    "\n",
    "    # Stack the original array and the column of ones\n",
    "    # return np.column_stack((biases, weights ))\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3df93d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compute_forward(inputs, layer):\n",
    "    ## linear combination w0x0 + w1x1 + w2x2\n",
    "    linear_combinations = []\n",
    "    # print(inputs, inputs.shape)\n",
    "    # print(np.ones(inputs.shape[1]))\n",
    "    inputs = np.c_[ np.ones(inputs.shape[0]), inputs  ]    ## add bias to the inputs\n",
    "    # print(inputs)\n",
    "    # print(layer)\n",
    "\n",
    "    linear_combinations = np.matmul(inputs, layer.T) ## logits or z\n",
    "    \n",
    "    # print(linear_combinations)\n",
    "\n",
    "    sigmoids = 1/(  1 + np.exp( -linear_combinations ) ) ## compute a\n",
    "    # print(sigmoids)\n",
    "\n",
    "    return linear_combinations, sigmoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0ba3436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy_loss(output_sigmoids, target):\n",
    "    \n",
    "    ## m is number of samples\n",
    "    ## k is total number of output units\n",
    "\n",
    "    log_sigmoids = np.log(output_sigmoids)\n",
    "    y_times_log_sigmoids = np.matmul(log_sigmoids, target.T)\n",
    "    # print(y_times_log_sigmoids)\n",
    "\n",
    "    one_minus_log_sigmoids = 1 - np.log(output_sigmoids)\n",
    "    one_minus_y_times_log_sigmoids = np.matmul(one_minus_log_sigmoids, (1 - target).T)\n",
    "    # print(one_minus_y_times_log_sigmoids)\n",
    "    \n",
    "    return sum(sum((y_times_log_sigmoids + one_minus_y_times_log_sigmoids)))/len(target) ## sum across the output units and sum across the samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cded2821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_backpropogation(sigmoids: list, layers: list, y, x):\n",
    "    \"\"\"\"\"\"\n",
    "    # layers = [hidden_layer1, output_layer]\n",
    "    layers.reverse()\n",
    "    # sigmoids = [sigmoids2, output_sigmoids]\n",
    "    sigmoids.insert(0, x)\n",
    "    sigmoids.reverse()\n",
    "    gradients = []\n",
    "\n",
    "\n",
    "    for i, layer in enumerate(layers):\n",
    "        if i == 0:\n",
    "            delta = (sigmoids[i] - y)\n",
    "            # print(delta.shape)\n",
    "            previous_sigmoids = np.c_[ np.ones(sigmoids[i+1].shape[0]), sigmoids[i+1]  ]    ## add bias to the inputs\n",
    "            # print(sigmoids[i])\n",
    "            # print(\"__ __ __ __\")\n",
    "            # print(previous_sigmoids)\n",
    "\n",
    "            ## delta has shape (samples x nodes)\n",
    "            ## sigmoids has shape (samples x activations + 1)\n",
    "            ## ex delta = sx2 (s = samples & nodes = 2 )\n",
    "            ##    sigmoids = sx3 (s = samples & there are 2 sigmoids and 1 to multiple the bias by)\n",
    "            gradients.append(np.matmul(delta.T, previous_sigmoids))\n",
    "\n",
    "\n",
    "        else:\n",
    "            # print(\"_______________________________\")\n",
    "            ## after the first delta, every previous delta is\n",
    "            ## (delta * (weights from the previous layer)) * sigmoids or x\n",
    "            delta = np.matmul(delta, layers[i-1][:,1:]) * sigmoids[i] * (1- sigmoids[i])\n",
    "            previous_sigmoids = np.c_[ np.ones(sigmoids[i+1].shape[0]), sigmoids[i+1]  ]    ## add bias to the inputs\n",
    "            # print(previous_sigmoids)\n",
    "            gradients.append(np.matmul(delta.T, previous_sigmoids))\n",
    "\n",
    "\n",
    "    # print(gradients)\n",
    "    return gradients\n",
    "\n",
    "def step(weights: list, gradients: list, lr = 0.001):\n",
    "    gradients.reverse()\n",
    "    for weight, gradient in zip(weights, gradients): ## so the first gradient is the input layers graidents\n",
    "        yield weight - (gradient * lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "44b238bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.55382914 0.85385375 0.19732555]\n",
      " [0.05187953 0.68335227 0.00962818]] [[0.72773258 0.49810198 0.82095659]]\n",
      "----------------------epoch: 0-----------------------\n",
      "predictions:\n",
      "[[1]\n",
      " [1]\n",
      " [1]]\n",
      "Actual:\n",
      "[[0]\n",
      " [1]\n",
      " [0]], \n",
      " [[0.81663454]\n",
      " [0.80852021]\n",
      " [0.81663454]]\n",
      "error: 2.2058922656628943\n",
      "[[0.81663454]\n",
      " [0.80852021]\n",
      " [0.81663454]]\n",
      "----------------------epoch: 1-----------------------\n",
      "predictions:\n",
      "[[1]\n",
      " [1]\n",
      " [1]]\n",
      "Actual:\n",
      "[[0]\n",
      " [1]\n",
      " [0]], \n",
      " [[0.79659073]\n",
      " [0.78865898]\n",
      " [0.79659073]]\n",
      "error: 2.2307499203998145\n",
      "[[0.79659073]\n",
      " [0.78865898]\n",
      " [0.79659073]]\n",
      "----------------------epoch: 2-----------------------\n",
      "predictions:\n",
      "[[1]\n",
      " [1]\n",
      " [1]]\n",
      "Actual:\n",
      "[[0]\n",
      " [1]\n",
      " [0]], \n",
      " [[0.77603028]\n",
      " [0.76836968]\n",
      " [0.77603028]]\n",
      "error: 2.256870593427961\n",
      "[[0.77603028]\n",
      " [0.76836968]\n",
      " [0.77603028]]\n",
      "----------------------epoch: 3-----------------------\n",
      "predictions:\n",
      "[[1]\n",
      " [1]\n",
      " [1]]\n",
      "Actual:\n",
      "[[0]\n",
      " [1]\n",
      " [0]], \n",
      " [[0.75516558]\n",
      " [0.74785476]\n",
      " [0.75516558]]\n",
      "error: 2.284060992023609\n",
      "[[0.75516558]\n",
      " [0.74785476]\n",
      " [0.75516558]]\n",
      "----------------------epoch: 4-----------------------\n",
      "predictions:\n",
      "[[1]\n",
      " [1]\n",
      " [1]]\n",
      "Actual:\n",
      "[[0]\n",
      " [1]\n",
      " [0]], \n",
      " [[0.73420635]\n",
      " [0.72731195]\n",
      " [0.73420635]]\n",
      "error: 2.3121100397887804\n",
      "[[0.73420635]\n",
      " [0.72731195]\n",
      " [0.73420635]]\n",
      "----------------------epoch: 5-----------------------\n",
      "predictions:\n",
      "[[1]\n",
      " [1]\n",
      " [1]]\n",
      "Actual:\n",
      "[[0]\n",
      " [1]\n",
      " [0]], \n",
      " [[0.71335091]\n",
      " [0.70692637]\n",
      " [0.71335091]]\n",
      "error: 2.3407974649212235\n",
      "[[0.71335091]\n",
      " [0.70692637]\n",
      " [0.71335091]]\n",
      "----------------------epoch: 6-----------------------\n",
      "predictions:\n",
      "[[1]\n",
      " [1]\n",
      " [1]]\n",
      "Actual:\n",
      "[[0]\n",
      " [1]\n",
      " [0]], \n",
      " [[0.69277911]\n",
      " [0.68686449]\n",
      " [0.69277911]]\n",
      "error: 2.369902138145814\n",
      "[[0.69277911]\n",
      " [0.68686449]\n",
      " [0.69277911]]\n",
      "----------------------epoch: 7-----------------------\n",
      "predictions:\n",
      "[[1]\n",
      " [1]\n",
      " [1]]\n",
      "Actual:\n",
      "[[0]\n",
      " [1]\n",
      " [0]], \n",
      " [[0.67264744]\n",
      " [0.66726989]\n",
      " [0.67264744]]\n",
      "error: 2.3992095269505556\n",
      "[[0.67264744]\n",
      " [0.66726989]\n",
      " [0.67264744]]\n",
      "----------------------epoch: 8-----------------------\n",
      "predictions:\n",
      "[[1]\n",
      " [1]\n",
      " [1]]\n",
      "Actual:\n",
      "[[0]\n",
      " [1]\n",
      " [0]], \n",
      " [[0.65308633]\n",
      " [0.64826121]\n",
      " [0.65308633]]\n",
      "error: 2.4285178281547695\n",
      "[[0.65308633]\n",
      " [0.64826121]\n",
      " [0.65308633]]\n",
      "----------------------epoch: 9-----------------------\n",
      "predictions:\n",
      "[[1]\n",
      " [1]\n",
      " [1]]\n",
      "Actual:\n",
      "[[0]\n",
      " [1]\n",
      " [0]], \n",
      " [[0.63419936]\n",
      " [0.62993174]\n",
      " [0.63419936]]\n",
      "error: 2.4576425568929383\n",
      "[[0.63419936]\n",
      " [0.62993174]\n",
      " [0.63419936]]\n",
      "----------------------epoch: 10-----------------------\n",
      "predictions:\n",
      "[[1]\n",
      " [1]\n",
      " [1]]\n",
      "Actual:\n",
      "[[0]\n",
      " [1]\n",
      " [0]], \n",
      " [[0.61606418]\n",
      " [0.61235051]\n",
      " [0.61606418]]\n",
      "error: 2.486419566325345\n",
      "[[0.61606418]\n",
      " [0.61235051]\n",
      " [0.61606418]]\n",
      "----------------------epoch: 11-----------------------\n",
      "predictions:\n",
      "[[1]\n",
      " [1]\n",
      " [1]]\n",
      "Actual:\n",
      "[[0]\n",
      " [1]\n",
      " [0]], \n",
      " [[0.59873452]\n",
      " [0.59556432]\n",
      " [0.59873452]]\n",
      "error: 2.5147066230793738\n",
      "[[0.59873452]\n",
      " [0.59556432]\n",
      " [0.59873452]]\n",
      "----------------------epoch: 12-----------------------\n",
      "predictions:\n",
      "[[1]\n",
      " [1]\n",
      " [1]]\n",
      "Actual:\n",
      "[[0]\n",
      " [1]\n",
      " [0]], \n",
      " [[0.58224295]\n",
      " [0.57960043]\n",
      " [0.58224295]]\n",
      "error: 2.542383759026791\n",
      "[[0.58224295]\n",
      " [0.57960043]\n",
      " [0.58224295]]\n",
      "----------------------epoch: 13-----------------------\n",
      "predictions:\n",
      "[[1]\n",
      " [1]\n",
      " [1]]\n",
      "Actual:\n",
      "[[0]\n",
      " [1]\n",
      " [0]], \n",
      " [[0.56660403]\n",
      " [0.56446956]\n",
      " [0.56660403]]\n",
      "error: 2.5693526638043016\n",
      "[[0.56660403]\n",
      " [0.56446956]\n",
      " [0.56660403]]\n",
      "----------------------epoch: 14-----------------------\n",
      "predictions:\n",
      "[[1]\n",
      " [1]\n",
      " [1]]\n",
      "Actual:\n",
      "[[0]\n",
      " [1]\n",
      " [0]], \n",
      " [[0.55181744]\n",
      " [0.5501688 ]\n",
      " [0.55181744]]\n",
      "error: 2.5955353853689305\n",
      "[[0.55181744]\n",
      " [0.5501688 ]\n",
      " [0.55181744]]\n",
      "----------------------epoch: 15-----------------------\n",
      "predictions:\n",
      "[[1]\n",
      " [1]\n",
      " [1]]\n",
      "Actual:\n",
      "[[0]\n",
      " [1]\n",
      " [0]], \n",
      " [[0.53787105]\n",
      " [0.5366845 ]\n",
      " [0.53787105]]\n",
      "error: 2.6208725813368035\n",
      "[[0.53787105]\n",
      " [0.5366845 ]\n",
      " [0.53787105]]\n",
      "----------------------epoch: 16-----------------------\n",
      "predictions:\n",
      "[[1]\n",
      " [1]\n",
      " [1]]\n",
      "Actual:\n",
      "[[0]\n",
      " [1]\n",
      " [0]], \n",
      " [[0.52474363]\n",
      " [0.52399472]\n",
      " [0.52474363]]\n",
      "error: 2.645321524467065\n",
      "[[0.52474363]\n",
      " [0.52399472]\n",
      " [0.52474363]]\n",
      "----------------------epoch: 17-----------------------\n",
      "predictions:\n",
      "[[1]\n",
      " [1]\n",
      " [1]]\n",
      "Actual:\n",
      "[[0]\n",
      " [1]\n",
      " [0]], \n",
      " [[0.51240725]\n",
      " [0.51207153]\n",
      " [0.51240725]]\n",
      "error: 2.6688540212702065\n",
      "[[0.51240725]\n",
      " [0.51207153]\n",
      " [0.51240725]]\n",
      "----------------------epoch: 18-----------------------\n",
      "predictions:\n",
      "[[1]\n",
      " [1]\n",
      " [1]]\n",
      "Actual:\n",
      "[[0]\n",
      " [1]\n",
      " [0]], \n",
      " [[0.50082931]\n",
      " [0.50088276]\n",
      " [0.50082931]]\n",
      "error: 2.691454359973956\n",
      "[[0.50082931]\n",
      " [0.50088276]\n",
      " [0.50082931]]\n",
      "----------------------epoch: 19-----------------------\n",
      "predictions:\n",
      "[[0]\n",
      " [0]\n",
      " [0]]\n",
      "Actual:\n",
      "[[0]\n",
      " [1]\n",
      " [0]], \n",
      " [[0.48997417]\n",
      " [0.49039362]\n",
      " [0.48997417]]\n",
      "error: 2.713117366724609\n",
      "[[0.48997417]\n",
      " [0.49039362]\n",
      " [0.48997417]]\n"
     ]
    }
   ],
   "source": [
    "### put it all together:\n",
    "EPOCHS = 20\n",
    "x = np.array([[0.1,0.2],\n",
    "              [-.04,-0.6], \n",
    "              [0.1,0.2]]) # x1, x2\n",
    "\n",
    "# # y = np.array([[1,0],[1,1],[0,1]])\n",
    "y = np.array([[0],[1],[0]])\n",
    "\n",
    "\n",
    "seed(1)\n",
    "hidden_layer1 = Linear(2,2) \n",
    "seed(1)\n",
    "output_layer = Linear(2,1) \n",
    "\n",
    "print(hidden_layer1, output_layer)\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    z2, sigmoids2 = compute_forward(x, hidden_layer1)\n",
    "\n",
    "    z_output, output_sigmoids = compute_forward(sigmoids2, output_layer)\n",
    "\n",
    "    loss = binary_cross_entropy_loss(output_sigmoids, y)\n",
    "\n",
    "\n",
    "    # l2_gradients = compute_backpropogation(output_sigmoids, y, sigmoids2)\n",
    "\n",
    "\n",
    "    # l1_gradients = compute_backpropogation(sigmoids2, y, x)\n",
    "\n",
    "    # output_layer1 = step(hidden_layer1, l1_gradients, 0.1)\n",
    "\n",
    "    gradients = compute_backpropogation(sigmoids = [sigmoids2, output_sigmoids], layers = [hidden_layer1, output_layer], y=y, x=x)\n",
    "    hidden_layer1, output_layer = step(weights = [hidden_layer1, output_layer], gradients = gradients, lr = 0.05)\n",
    "    # print(gradients)\n",
    "    \n",
    "\n",
    "    print(f\"----------------------epoch: {epoch}-----------------------\")\n",
    "    print(f\"predictions:\\n{(output_sigmoids > 0.5).astype(int)}\\nActual:\\n{y}, \\n {output_sigmoids}\")\n",
    "    print(f\"error: {loss}\")\n",
    "    print(output_sigmoids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (machinelearning)",
   "language": "python",
   "name": "machinelearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
