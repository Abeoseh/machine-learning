{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef77b431",
   "metadata": {},
   "source": [
    "![\"question\"](question.jpg)\n",
    "\n",
    "\n",
    "\n",
    "between layer 1 and 2:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "  b_{10} & w_{11} & w_{21} \\\\\n",
    "  b_{20} & w_{12} & w_{22} \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "where b = bias and w = weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb473e93",
   "metadata": {},
   "source": [
    "$x = [0.1,0.2]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18bd8430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36e67c6",
   "metadata": {},
   "source": [
    "input is columns, output is rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4efc0c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Linear(num_nodes_input_layer, num_nodes_output_layer):\n",
    "    \"\"\"Dimensions: output is rows, input is columns.\"\"\"\n",
    "    weights = np.random.rand(num_nodes_output_layer, num_nodes_input_layer + 1) * 0.01\n",
    "    # biases = np.ones((weights.shape[0], 1))\n",
    "\n",
    "    # Stack the original array and the column of ones\n",
    "    # return np.column_stack((biases, weights ))\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422ae8ad",
   "metadata": {},
   "source": [
    "# Forward propogation to make predictions\n",
    "\n",
    "![\"how to apply the weights\"](apply_weights.png)\n",
    "\n",
    "$$ output = \n",
    "\\begin{bmatrix}\n",
    "  Neuron\\:1\\:applied\\:to\\:sample\\:1 & Neuron\\:2\\:applied\\:to\\:sample\\:1 \\\\\n",
    "  Neuron\\:1\\:applied\\:to\\:sample\\:2 & Neuron\\:2\\:applied\\:to\\:sample\\:2\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5fc97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_forward(inputs, layer):\n",
    "    ## linear combination w0x0 + w1x1 + w2x2\n",
    "    linear_combinations = []\n",
    "    inputs = np.c_[ np.ones(inputs.shape[0]), inputs  ]    ## add bias to the inputs\n",
    "\n",
    "    linear_combinations = np.matmul(inputs, layer.T) ## logits or z\n",
    "    \n",
    "    # print(linear_combinations)\n",
    "\n",
    "    sigmoids = 1/(  1 + np.exp( -linear_combinations ) ) ## compute a\n",
    "    # print(sigmoids)\n",
    "\n",
    "    return linear_combinations, sigmoids\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b64766b",
   "metadata": {},
   "source": [
    "# Loss function\n",
    "\n",
    "*m is number of samples*\n",
    "\n",
    "*k is total number of output units*\n",
    "$$\n",
    " J(θ)= - \\frac{1}{m} {\\sum^m_{i=1}\\sum^k_{k=1} [y^{(i)}_kln(\\frac{1}{1+e^{xθ^T}})_k + (1-y^{(i)}_k)ln(1-(\\frac{1}{1+e^{xθ^T}})_k)]} \n",
    "$$\n",
    "$$\n",
    " = \\frac{1}{m} {\\sum^m_{i=1}\\sum^k_{k=1} [y^{(i)}_kln(a^{(L)}_k) + (1-y^{(i)}_k)ln(1-a^{(L)}_k)]}\n",
    "\n",
    "$$\n",
    "\n",
    "\n",
    "$$  \n",
    "output\\_sigmoids = \n",
    "\\begin{bmatrix}\n",
    "  Neuron\\:1\\:applied\\:to\\:sample\\:1 & Neuron\\:2\\:applied\\:to\\:sample\\:1 \\\\\n",
    "  Neuron\\:1\\:applied\\:to\\:sample\\:2 & Neuron\\:2\\:applied\\:to\\:sample\\:2\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3ad834a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy_loss(output_sigmoids, target):\n",
    "    \n",
    "    ## m is number of samples\n",
    "    ## k is total number of output units\n",
    "\n",
    "    target = target.reshape(-1,1)\n",
    "    log_sigmoids = np.log(output_sigmoids)\n",
    "    y_times_log_sigmoids = log_sigmoids * target ## element-wise multiplication\n",
    "\n",
    "    one_minus_log_sigmoids = np.log(1 - output_sigmoids)\n",
    "    one_minus_y_times_log_sigmoids = one_minus_log_sigmoids * (1 - target) ## element-wise multiplication\n",
    "    # print(one_minus_y_times_log_sigmoids)\n",
    "    \n",
    "    return sum(sum((y_times_log_sigmoids + one_minus_y_times_log_sigmoids)))/len(target) * -1 ## sum across the output units and sum across the samples\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d308077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_backpropogation(sigmoids: list, layers: list, y, x):\n",
    "    \"\"\"\"\"\"\n",
    "    layers.reverse()\n",
    "\n",
    "    sigmoids.insert(0, x)     \n",
    "    sigmoids.reverse()\n",
    "    gradients = []\n",
    "\n",
    "    y = y.reshape(-1,1)\n",
    "    # print(y)\n",
    "\n",
    "    for i, layer in enumerate(layers):\n",
    "        if i == 0:\n",
    "\n",
    "            delta = (sigmoids[i] - y)\n",
    "            # print(delta.shape)\n",
    "            previous_sigmoids = np.c_[ np.ones(sigmoids[i+1].shape[0]), sigmoids[i+1]  ]    ## add bias to the inputs\n",
    "\n",
    "\n",
    "            ## delta has shape (samples x nodes)\n",
    "            ## sigmoids has shape (samples x activations + 1)\n",
    "            ## ex delta = sx2 (s = samples & nodes = 2 )\n",
    "            ##    sigmoids = sx3 (s = samples & there are 2 sigmoids and 1 to multiple the bias by)\n",
    "            gradients.append(1/x.shape[0]*np.matmul(delta.T, previous_sigmoids))\n",
    "\n",
    "\n",
    "        else:\n",
    "            ## after the first delta, every previous delta is\n",
    "            ## (delta * (weights from the previous layer)) * sigmoids or x\n",
    "            delta = np.matmul(delta, layers[i-1][:,1:]) * sigmoids[i] * (1- sigmoids[i])\n",
    "            previous_sigmoids = np.c_[ np.ones(sigmoids[i+1].shape[0]), sigmoids[i+1]  ]    ## add bias to the inputs\n",
    "            # print(previous_sigmoids)\n",
    "            gradients.append(1/x.shape[0]*np.matmul(delta.T, previous_sigmoids))\n",
    "\n",
    "\n",
    "    # print(gradients)\n",
    "    return gradients\n",
    "\n",
    "def step(weights: list, gradients: list, lr = 0.01):\n",
    "    # updated_weights = []\n",
    "    gradients.reverse()\n",
    "    for weight, gradient in zip(weights, gradients): ## so the first gradient is the input layers graidents\n",
    "        yield weight - (gradient * lr)\n",
    "        # weight = weight + (gradient * lr)\n",
    "        # updated_weights.append(weight)\n",
    "\n",
    "    # return updated_weights\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "236c0c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "target = iris.target[(iris.target == 0) | (iris.target == 1)]\n",
    "data = iris.data[(iris.target == 0) | (iris.target == 1)][:, :2]\n",
    "\n",
    "indices = np.random.permutation(target.shape[0])\n",
    "training_idx, test_idx = indices[:int(target.shape[0] * .7)], indices[int(target.shape[0] * .3):]\n",
    "target_training, target_test = target[training_idx], target[test_idx]\n",
    "data_training, data_test = data[training_idx], data[test_idx]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66e709e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------epoch: 0-----------------------\n",
      "predictions:\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.6931654887110626\n",
      "correct prediction rate: 50.0%\n",
      "----------------------epoch: 100-----------------------\n",
      "predictions:\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.693142351083335\n",
      "correct prediction rate: 50.0%\n",
      "----------------------epoch: 200-----------------------\n",
      "predictions:\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.6931286980094766\n",
      "correct prediction rate: 50.0%\n",
      "----------------------epoch: 300-----------------------\n",
      "predictions:\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.6930771779182805\n",
      "correct prediction rate: 50.0%\n",
      "----------------------epoch: 400-----------------------\n",
      "predictions:\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.6928849455695016\n",
      "correct prediction rate: 50.0%\n",
      "----------------------epoch: 500-----------------------\n",
      "predictions:\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.6922016366479039\n",
      "correct prediction rate: 50.0%\n",
      "----------------------epoch: 600-----------------------\n",
      "predictions:\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.6899558279222308\n",
      "correct prediction rate: 50.0%\n",
      "----------------------epoch: 700-----------------------\n",
      "predictions:\n",
      "[1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1\n",
      " 1 1 0 1 1 0 1 0 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.6827422932966369\n",
      "correct prediction rate: 71.42857142857143%\n",
      "----------------------epoch: 800-----------------------\n",
      "predictions:\n",
      "[1 0 1 0 0 0 0 0 1 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.6597606713323841\n",
      "correct prediction rate: 97.14285714285714%\n",
      "----------------------epoch: 900-----------------------\n",
      "predictions:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.5972912816135261\n",
      "correct prediction rate: 100.0%\n",
      "----------------------epoch: 1000-----------------------\n",
      "predictions:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.48018269921957507\n",
      "correct prediction rate: 100.0%\n",
      "----------------------epoch: 1100-----------------------\n",
      "predictions:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.34815612581149\n",
      "correct prediction rate: 100.0%\n",
      "----------------------epoch: 1200-----------------------\n",
      "predictions:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.2474819778173177\n",
      "correct prediction rate: 100.0%\n",
      "----------------------epoch: 1300-----------------------\n",
      "predictions:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.1820335679103006\n",
      "correct prediction rate: 100.0%\n",
      "----------------------epoch: 1400-----------------------\n",
      "predictions:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.14003758300893143\n",
      "correct prediction rate: 100.0%\n",
      "----------------------epoch: 1500-----------------------\n",
      "predictions:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.11206698780815348\n",
      "correct prediction rate: 100.0%\n",
      "----------------------epoch: 1600-----------------------\n",
      "predictions:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.09256551400471294\n",
      "correct prediction rate: 100.0%\n",
      "----------------------epoch: 1700-----------------------\n",
      "predictions:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.07838760317959831\n",
      "correct prediction rate: 100.0%\n",
      "----------------------epoch: 1800-----------------------\n",
      "predictions:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.0677070132430907\n",
      "correct prediction rate: 100.0%\n",
      "----------------------epoch: 1900-----------------------\n",
      "predictions:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.05941914827587217\n",
      "correct prediction rate: 100.0%\n",
      "----------------------epoch: 2000-----------------------\n",
      "predictions:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.05282730176142735\n",
      "correct prediction rate: 100.0%\n",
      "----------------------epoch: 2100-----------------------\n",
      "predictions:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.04747478110942969\n",
      "correct prediction rate: 100.0%\n",
      "----------------------epoch: 2200-----------------------\n",
      "predictions:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.04305182143292403\n",
      "correct prediction rate: 100.0%\n",
      "----------------------epoch: 2300-----------------------\n",
      "predictions:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.03934192996234604\n",
      "correct prediction rate: 100.0%\n",
      "----------------------epoch: 2400-----------------------\n",
      "predictions:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.03618978545888632\n",
      "correct prediction rate: 100.0%\n",
      "----------------------epoch: 2500-----------------------\n",
      "predictions:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.03348136434312429\n",
      "correct prediction rate: 100.0%\n",
      "----------------------epoch: 2600-----------------------\n",
      "predictions:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.031131249636332667\n",
      "correct prediction rate: 100.0%\n",
      "----------------------epoch: 2700-----------------------\n",
      "predictions:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.029074298088599335\n",
      "correct prediction rate: 100.0%\n",
      "----------------------epoch: 2800-----------------------\n",
      "predictions:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.027260030543170242\n",
      "correct prediction rate: 100.0%\n",
      "----------------------epoch: 2900-----------------------\n",
      "predictions:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.025648769872885335\n",
      "correct prediction rate: 100.0%\n",
      "----------------------epoch: 3000-----------------------\n",
      "predictions:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.024208927762345588\n",
      "correct prediction rate: 100.0%\n",
      "----------------------epoch: 3100-----------------------\n",
      "predictions:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.02291506343455758\n",
      "correct prediction rate: 100.0%\n",
      "----------------------epoch: 3200-----------------------\n",
      "predictions:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.021746471479352072\n",
      "correct prediction rate: 100.0%\n",
      "----------------------epoch: 3300-----------------------\n",
      "predictions:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.020686138959147293\n",
      "correct prediction rate: 100.0%\n",
      "----------------------epoch: 3400-----------------------\n",
      "predictions:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.019719964542319977\n",
      "correct prediction rate: 100.0%\n",
      "----------------------epoch: 3500-----------------------\n",
      "predictions:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.018836166401439335\n",
      "correct prediction rate: 100.0%\n",
      "----------------------epoch: 3600-----------------------\n",
      "predictions:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.018024828004351352\n",
      "correct prediction rate: 100.0%\n",
      "----------------------epoch: 3700-----------------------\n",
      "predictions:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.01727754593685687\n",
      "correct prediction rate: 100.0%\n",
      "----------------------epoch: 3800-----------------------\n",
      "predictions:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.016587154122523068\n",
      "correct prediction rate: 100.0%\n",
      "----------------------epoch: 3900-----------------------\n",
      "predictions:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.015947505877479642\n",
      "correct prediction rate: 100.0%\n",
      "----------------------epoch: 4000-----------------------\n",
      "predictions:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.015353300197150107\n",
      "correct prediction rate: 100.0%\n",
      "----------------------epoch: 4100-----------------------\n",
      "predictions:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.014799942194302619\n",
      "correct prediction rate: 100.0%\n",
      "----------------------epoch: 4200-----------------------\n",
      "predictions:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.014283430140030657\n",
      "correct prediction rate: 100.0%\n",
      "----------------------epoch: 4300-----------------------\n",
      "predictions:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.013800263400207532\n",
      "correct prediction rate: 100.0%\n",
      "----------------------epoch: 4400-----------------------\n",
      "predictions:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.0133473669124555\n",
      "correct prediction rate: 100.0%\n",
      "----------------------epoch: 4500-----------------------\n",
      "predictions:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.012922028852166782\n",
      "correct prediction rate: 100.0%\n",
      "----------------------epoch: 4600-----------------------\n",
      "predictions:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.012521848887586052\n",
      "correct prediction rate: 100.0%\n",
      "----------------------epoch: 4700-----------------------\n",
      "predictions:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.01214469499163685\n",
      "correct prediction rate: 100.0%\n",
      "----------------------epoch: 4800-----------------------\n",
      "predictions:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.011788667210533668\n",
      "correct prediction rate: 100.0%\n",
      "----------------------epoch: 4900-----------------------\n",
      "predictions:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "Actual:\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1]\n",
      "error: 0.011452067121088752\n",
      "correct prediction rate: 100.0%\n"
     ]
    }
   ],
   "source": [
    "### put it all together:\n",
    "EPOCHS = 5000\n",
    "\n",
    "#### lists for plotting ####\n",
    "loss_list = []\n",
    "\n",
    "\n",
    "hidden_layer1 = Linear(2,2) ## weights and biases\n",
    "\n",
    "output_layer = Linear(2,1) ## weights and biases\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "\n",
    "    z2, sigmoids2 = compute_forward(data_training, hidden_layer1)\n",
    "\n",
    "    z_output, output_sigmoids = compute_forward(sigmoids2, output_layer)\n",
    "\n",
    "    loss = binary_cross_entropy_loss(output_sigmoids, target_training)\n",
    "    loss_list.append(loss)\n",
    "\n",
    "    gradients = compute_backpropogation(sigmoids = [sigmoids2, output_sigmoids], layers = [hidden_layer1, output_layer], y=target_training, x=data_training)\n",
    "    hidden_layer1, output_layer = step(weights = [hidden_layer1, output_layer], gradients = gradients, lr = 0.1)\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"----------------------epoch: {epoch}-----------------------\")\n",
    "        print(f\"predictions:\\n{(output_sigmoids.reshape(target_training.shape) > 0.5).astype(int)}\\nActual:\\n{target_training}\")\n",
    "        print(f\"error: {loss}\")\n",
    "        print(f\"correct prediction rate: {sum( (output_sigmoids.reshape(target_training.shape) > 0.5).astype(int) == target_training ) / len(target_training) * 100}%\")\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d29254",
   "metadata": {},
   "source": [
    "### Make plots of loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10ab4954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "## plot loss\n",
    "plt.plot(loss_list)\n",
    "plt.title(\"Total Cost vs Iterations\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e1bfae",
   "metadata": {},
   "source": [
    "#### test on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "806c92ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions:\n",
      "[0 0 1 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0\n",
      " 0 1 1 0 0 0 0 1 0 0 1 0 0 0 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 0 1 1]\n",
      "Actual:\n",
      "[0 0 1 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0\n",
      " 0 1 1 0 0 0 0 1 0 0 1 0 0 0 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 0 0 1]\n",
      "error: 0.06462602493834302\n",
      "correct predictions rate: 98.57142857142858%\n"
     ]
    }
   ],
   "source": [
    "z2, sigmoids2 = compute_forward(data_test, hidden_layer1)\n",
    "z_output, output_sigmoids = compute_forward(sigmoids2, output_layer)\n",
    "\n",
    "loss = binary_cross_entropy_loss(output_sigmoids, target_test)\n",
    "\n",
    "print(f\"predictions:\\n{(output_sigmoids.reshape(target_test.shape) > 0.5).astype(int)}\\nActual:\\n{target_test}\")\n",
    "print(f\"error: {loss}\")\n",
    "\n",
    "print(f\"correct predictions rate: {sum( (output_sigmoids.reshape(target_test.shape) > 0.5).astype(int) == target_test ) / len(target_test) * 100 }%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3272d0d2",
   "metadata": {},
   "source": [
    "# Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ddc3631f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn MLP Accuracy: 0.9857142857142858\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "sk_model = MLPClassifier(hidden_layer_sizes=(2,), activation='logistic',\n",
    "                         learning_rate_init=0.1, max_iter=5000, solver='sgd',random_state=1)\n",
    "\n",
    "sk_model.fit(data_training, target_training)\n",
    "sk_pred = sk_model.predict(data_test)\n",
    "# sk_pred = sk_model.predict(data_training)\n",
    "\n",
    "# loss = sk_model.loss_curve_\n",
    "\n",
    "print(\"Sklearn MLP Accuracy:\", accuracy_score(target_test, sk_pred))\n",
    "# print(\"Sklearn MLP Accuracy:\", accuracy_score(target_training, sk_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c22ac2",
   "metadata": {},
   "source": [
    "# Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c12b3522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4310957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------epoch 1000--------------------------------------\n",
      "                  loss: 0.24123366177082062\n",
      "predictions:\n",
      "tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
      "        1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "Actual:\n",
      "tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.])\n",
      "correct prediction rate: 100.0%\n",
      "------------------------------epoch 2000--------------------------------------\n",
      "                  loss: 0.07759696245193481\n",
      "predictions:\n",
      "tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
      "        1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "Actual:\n",
      "tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.])\n",
      "correct prediction rate: 100.0%\n",
      "------------------------------epoch 3000--------------------------------------\n",
      "                  loss: 0.04296324402093887\n",
      "predictions:\n",
      "tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
      "        1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "Actual:\n",
      "tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.])\n",
      "correct prediction rate: 100.0%\n",
      "------------------------------epoch 4000--------------------------------------\n",
      "                  loss: 0.029133265838027\n",
      "predictions:\n",
      "tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
      "        1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "Actual:\n",
      "tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.])\n",
      "correct prediction rate: 100.0%\n",
      "------------------------------epoch 5000--------------------------------------\n",
      "                  loss: 0.02184281311929226\n",
      "predictions:\n",
      "tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
      "        1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "Actual:\n",
      "tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.])\n",
      "correct prediction rate: 100.0%\n",
      "----------------predictions---------------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype, but got Double and Float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 58\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m----------------predictions---------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     57\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(torch\u001b[38;5;241m.\u001b[39mtensor( data_test )\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32))\n\u001b[1;32m---> 58\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_test\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, torch\u001b[38;5;241m.\u001b[39mtensor( target_training )\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat64)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mloss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictions:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mpredictions\u001b[38;5;241m.\u001b[39mreshape(target_training\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\brean\\miniconda3\\envs\\machinelearning\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\brean\\miniconda3\\envs\\machinelearning\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[47], line 14\u001b[0m, in \u001b[0;36mANN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# print(x)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# x = self.input(x)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# x = torch.sigmoid(x)\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_layer1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(x)\n\u001b[0;32m     16\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer(x)\n",
      "File \u001b[1;32mc:\\Users\\brean\\miniconda3\\envs\\machinelearning\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\brean\\miniconda3\\envs\\machinelearning\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\brean\\miniconda3\\envs\\machinelearning\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    131\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m    Runs the forward pass.\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype, but got Double and Float"
     ]
    }
   ],
   "source": [
    "class ANN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        # self.input = nn.Linear(2,2)\n",
    "        self.hidden_layer1 = nn.Linear(2,2)\n",
    "        self.output_layer = nn.Linear(2,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x)\n",
    "        # x = self.input(x)\n",
    "        # x = torch.sigmoid(x)\n",
    "        x = self.hidden_layer1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        x = self.output_layer(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def predict(self, x):\n",
    "        x = self.forward(x)\n",
    "        return (torch.sigmoid(x) > 0.5).to(torch.int16)\n",
    "    \n",
    "model = ANN()\n",
    "x_vec = torch.tensor( data_training ).to(torch.float32)\n",
    "tensor_target = torch.tensor(target_training).to(torch.float32)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.05)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "EPOCHS = 5000\n",
    "for epoch in range(EPOCHS):\n",
    "    optimizer.zero_grad() ## remove old gradients\n",
    "\n",
    "\n",
    "    # ----- Forward Propagation -----\n",
    "    output = model(x_vec)\n",
    "\n",
    "    # ----- Compute Loss -----\n",
    "    loss = criterion(output, tensor_target.reshape(-1,1))\n",
    "\n",
    "    # ----- Backpropagation -----\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    output = torch.sigmoid(output)\n",
    "\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"------------------------------epoch {epoch+1}--------------------------------------\")\n",
    "        print(f\"                  loss: {loss}\")\n",
    "        print(f\"predictions:\\n{(output.reshape(tensor_target.shape) > 0.5).int()}\\nActual:\\n{tensor_target}\")\n",
    "        print(f\"correct prediction rate: {sum( (output.reshape(tensor_target.shape) > 0.5).int() == tensor_target ) / len(tensor_target) * 100}%\")\n",
    "        # print(tensor_target)\n",
    "        ## get amount of correct predictions\n",
    "\n",
    "print(f\"----------------predictions---------------------------\")\n",
    "predictions = model.predict(torch.tensor( data_test ).to(torch.float32))\n",
    "loss = criterion(model(torch.tensor( data_test ).to(torch.float32)), torch.tensor( target_training ).to(torch.float32).reshape(-1,1))\n",
    "print(f\"\\t\\tloss: {loss}\")\n",
    "print(f\"predictions:\\n{predictions.reshape(target_training.shape)}\")\n",
    "print(f\"Actual:\\n{torch.tensor( target_training ).to(torch.float32)}\")\n",
    "print(f\"correct prediction rate: {sum( predictions.reshape(target_training.shape) == torch.tensor( target_training ).to(torch.float32) ) / len(target_training) * 100}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
