{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef77b431",
   "metadata": {},
   "source": [
    "![\"question\"](question.jpg)\n",
    "\n",
    "\n",
    "\n",
    "between layer 1 and 2:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "  b_{10} & w_{11} & w_{21} \\\\\n",
    "  b_{20} & w_{12} & w_{22} \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "where b = bias and w = weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb473e93",
   "metadata": {},
   "source": [
    "$x = [0.1,0.2]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "18bd8430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f482b602",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[0.1,0.2],\n",
    "      [0.3,0.8]]) # x1, x2\n",
    "\n",
    "# x = [[0.1,0.2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36e67c6",
   "metadata": {},
   "source": [
    "input is columns, output is rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4efc0c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Linear(num_nodes_input_layer, num_nodes_output_layer):\n",
    "    \"\"\"Dimensions: output is rows, input is columns.\"\"\"\n",
    "    seed(1)\n",
    "    weights = np.random.rand(num_nodes_output_layer, num_nodes_input_layer + 1)\n",
    "    # biases = np.ones((weights.shape[0], 1))\n",
    "\n",
    "    # Stack the original array and the column of ones\n",
    "    # return np.column_stack((biases, weights ))\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a7d05eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.83057883, 0.44581712, 0.35657956],\n",
       "       [0.09503414, 0.49783754, 0.6120248 ]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## define the layers\n",
    "seed(1)\n",
    "input = Linear(2,2)\n",
    "seed(1)\n",
    "hidden_layer1 = Linear(2,2)\n",
    "seed(1)\n",
    "output_layer = Linear(2,2)\n",
    "\n",
    "hidden_layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b4593819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return np.array([1/(  1 + np.exp( -linear_combination )  ) for linear_combination in  z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5fc97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_forward(inputs, layer):\n",
    "    ## linear combination w0x0 + w1x1 + w2x2\n",
    "    linear_combinations = []\n",
    "\n",
    "    inputs = np.c_[ np.ones(x.shape[1]), x  ]    ## add bias to the inputs\n",
    "\n",
    "    ## for each row in x, compute z for every node\n",
    "    for row in layer:\n",
    "        print(row)\n",
    "        print(\"----\")\n",
    "        linear_combinations.append( sum([input * weights_bias for input, weights_bias in zip(inputs, row)]) )\n",
    "\n",
    "\n",
    "    print(linear_combinations)\n",
    "\n",
    "    # sigmoids = [1/(  1 + np.exp( -linear_combination )  ) for linear_combination in  linear_combinations] ## compute a\n",
    "    # print(linear_combinations)\n",
    "    # print(sigmoids)\n",
    "\n",
    "    return sigmoid(linear_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f13c3bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69461823 0.21704253 0.32161864]\n",
      "----\n",
      "[0.57392364 0.09668728 0.35794559]\n",
      "----\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 2 is different from 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[129], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m a2 \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# a3 = compute_forward(a2, hidden_layer1)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# output = compute_forward(a3, output_layer)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# a2, a3, output\u001b[39;00m\n\u001b[0;32m      7\u001b[0m x\n",
      "Cell \u001b[1;32mIn[128], line 13\u001b[0m, in \u001b[0;36mcompute_forward\u001b[1;34m(inputs, layer)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m----\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m     linear_combinations\u001b[38;5;241m.\u001b[39mappend( \u001b[38;5;28msum\u001b[39m([\u001b[38;5;28minput\u001b[39m \u001b[38;5;241m*\u001b[39m weights_bias \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28minput\u001b[39m, weights_bias \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(inputs, row)]) )\n\u001b[1;32m---> 13\u001b[0m linear_combinations \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m \u001b[38;5;66;03m## compute z\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(linear_combinations)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# sigmoids = [1/(  1 + np.exp( -linear_combination )  ) for linear_combination in  linear_combinations] ## compute a\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# print(linear_combinations)\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# print(sigmoids)\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 2 is different from 3)"
     ]
    }
   ],
   "source": [
    "a2 = compute_forward(x, input)\n",
    "\n",
    "# a3 = compute_forward(a2, hidden_layer1)\n",
    "\n",
    "# output = compute_forward(a3, output_layer)\n",
    "# a2, a3, output\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f3ad834a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy_loss(output, target):\n",
    "    \n",
    "    ## m is number of samples\n",
    "    ## k is total number of output units\n",
    "    print(output)\n",
    "    for row in output:\n",
    "        print(row)\n",
    "        # for unit in row: ## two output units\n",
    "        #     print(unit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a7262e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62866359 0.79421103]\n",
      "0.6286635948125413\n",
      "0.7942110298247739\n"
     ]
    }
   ],
   "source": [
    "binary_cross_entropy_loss(output, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7755d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_backpropogation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6457fdc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13692008, 0.4647963 ],\n",
       "       [0.65395656, 0.00602726]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def forward(inputs):\n",
    "    inputs = in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c12b3522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a4310957",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        self.input = nn.Linear(2,2)\n",
    "        self.hidden_layer1 = nn.Linear(2,2)\n",
    "        self.output_layer = nn.Linear(2,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        x = self.hidden_layer1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        x = self.output_layer(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "model = ANN()\n",
    "\n",
    "x_vec = torch.tensor( [0.1,0.2] )\n",
    "target = torch.tensor([1.0, 2])\n",
    "\n",
    "# ----- Forward Propagation -----\n",
    "output = model(x_vec)\n",
    "\n",
    "# ----- Compute Loss -----\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "loss = criterion(output, target)\n",
    "\n",
    "# ----- Backpropagation -----\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)\n",
    "optimizer.zero_grad() ## remove old gradients\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (machinelearning)",
   "language": "python",
   "name": "machinelearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
